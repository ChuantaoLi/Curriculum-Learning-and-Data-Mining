{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-24T13:01:34.213901Z",
     "start_time": "2025-06-24T13:01:34.169893Z"
    }
   },
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trans = transforms.ToTensor()\n",
    "mnist_train = torchvision.datasets.FashionMNIST(\n",
    "    root=\"../data\", train=True, transform=trans, download=True)\n",
    "mnist_test = torchvision.datasets.FashionMNIST(\n",
    "    root=\"../data\", train=False, transform=trans, download=True)\n",
    "\n",
    "batch_size = 256\n",
    "train_iter = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "test_iter = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:01:34.222410Z",
     "start_time": "2025-06-24T13:01:34.218409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_inputs = 784  # 图片的长宽为28 x 28\n",
    "num_outputs = 10  # 输出类别数"
   ],
   "id": "7770414e1182431",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:01:34.236155Z",
     "start_time": "2025-06-24T13:01:34.232699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "w = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)\n",
    "b = torch.zeros(num_outputs, requires_grad=True)\n",
    "\n",
    "# q:为什么w的形状是(num_inputs, num_outputs)，而不是(num_inputs, 1)？\n",
    "# a:因为每个输入样本对应一个输出类别，所以需要为每个类别设置一个权重向量。\n",
    "# q:那为什么线性回归里面，w的列数是1？\n",
    "# a:因为线性回归是单输出模型，每个输入样本对应一个连续值，而Softmax回归是多分类模型，每个输入样本对应多个类别的概率分布。\n",
    "# q:那么，softmax输出的形状是什么样的？\n",
    "# a:softmax输出的形状是(batch_size, num_outputs)，其中batch_size是输入样本的数量，num_outputs是类别数。\n",
    "# q:如何理解线性回归输出的形状和softmax输出的形状，尤其是num_outputs列？\n",
    "# a:线性回归的输出是一个连续值，而softmax的输出是一个概率分布，其中num_outputs列表示每个类别的概率。"
   ],
   "id": "ac08f409930af354",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:01:34.248936Z",
     "start_time": "2025-06-24T13:01:34.244933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def softmax(X):\n",
    "    X_exp = X.exp()\n",
    "    partition = X_exp.sum(axis=1, keepdims=True)  # 计算每行的总和，结果是列向量\n",
    "    return X_exp / partition  # 广播机制"
   ],
   "id": "1fae3d061a7142a5",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:01:34.263987Z",
     "start_time": "2025-06-24T13:01:34.259909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def net(X):\n",
    "    return softmax(torch.matmul(X.reshape((-1, num_inputs)), w) + b)\n",
    "\n",
    "\n",
    "#q: 这里的-1表示什么？\n",
    "#a:-1表示任意大小，即任意的行数，列数都是任意的。\n",
    "#q: 为什么要reshape？为什么要-1？\n",
    "#a:因为输入的X是一个多维张量，我们需要将其展平为二维张量，以便进行矩阵乘法。-1表示自动计算行数，列数为num_inputs。\n",
    "print(mnist_train.data.shape)  # torch.Size([60000, 28, 28])"
   ],
   "id": "45379c5979dfe6c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:01:34.290556Z",
     "start_time": "2025-06-24T13:01:34.287188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    return -torch.log(y_hat[range(len(y_hat)), y])\n",
    "\n",
    "# q: y_hat的形状是什么样的？\n",
    "# a: y_hat的形状是(batch_size, num_outputs)。\n",
    "# q: y的形状是什么样的？\n",
    "# a: y的形状是(batch_size,)，表示每个样本的真实标签。\n",
    "# q: 如何理解y_hat[range(len(y_hat)), y]？\n",
    "# a: y_hat[range(len(y_hat)), y]表示从y_hat中取出每个样本对应的真实标签的概率值，结果是一个一维张量，形状为(batch_size,)。"
   ],
   "id": "daa2cdafda548f9d",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:01:34.312536Z",
     "start_time": "2025-06-24T13:01:34.308124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def accuracy(y_hat, y):\n",
    "#     if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "#         y_hat = y_hat.argmax(axis=1)  # 取出每行的最大值索引，就是预测的类别\n",
    "#     cmp = y_hat.type(y.dtype) == y  # 将y_hat转换为与y相同的数据类型，然后进行比较\n",
    "#     return float(cmp.type(y.dtype).sum())\n",
    "\n",
    "def accuracy(y_hat, y):\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    # 确保 y 是 Tensor\n",
    "    if not isinstance(y, torch.Tensor):\n",
    "        y = torch.tensor(y)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(torch.float).sum().item())"
   ],
   "id": "b8d86c93e3c8f62",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:01:34.319852Z",
     "start_time": "2025-06-24T13:01:34.316227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Accumulator:\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        for i, arg in enumerate(args):\n",
    "            self.data[i] += arg\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ],
   "id": "d8284401a1ac2459",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:01:34.334062Z",
     "start_time": "2025-06-24T13:01:34.328660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def evaluate_accuracy(net, data_iter):\n",
    "#     if isinstance(net, torch.nn.Module):\n",
    "#         net.eval()  # 设置为评估模式\n",
    "#     metric = Accumulator(2)  # 累加器，用于计算正确预测的数量和总样本数\n",
    "#     for X, y in data_iter:\n",
    "#         metric.add(accuracy(net(X), y), y.numel())\n",
    "#     return metric[0] / metric[1]  # 返回正确预测的比例\n",
    "\n",
    "def evaluate_accuracy(net, data_iter):\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()  # 设置为评估模式\n",
    "    metric = Accumulator(2)  # (正确预测数, 总样本数)\n",
    "    for X, y in data_iter:\n",
    "        with torch.no_grad():\n",
    "            y_hat = net(X)\n",
    "            acc = accuracy(y_hat, y)\n",
    "            metric.add(acc, y.numel())  # y 必须是 Tensor\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "# q: 什么是评估模式？\n",
    "# a: 评估模式是指模型在评估阶段的状态，此时会关闭一些训练时特有的操作，如dropout和batch normalization的训练模式。\n",
    "# q: 什么是metric = Accumulator(2)？\n",
    "# a: Accumulator是一个累加器，用于存储多个值，这里我们用它来存储正确预测的数量和总样本数。\n",
    "# q: Accumulator(2)的2表示什么？\n",
    "# a: 2表示我们需要存储两个值：正确预测的数量和总样本数。\n",
    "# q: y.numel()是什么？\n",
    "# a: y.numel()返回y张量中的元素总数，这里表示当前批次的样本数量。\n",
    "# q: 什么是isinstance()?\n",
    "# a: isinstance()是一个内置函数，用于检查一个对象是否是指定的类或数据类型的实例。"
   ],
   "id": "4b44f4cc00b336e",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:01:34.351463Z",
     "start_time": "2025-06-24T13:01:34.346036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_epoch_ch3(net, train_iter, loss, updater):\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()  # 设置为训练模式\n",
    "    metric = Accumulator(3)  # 累加器，用于计算总损失、正确预测的数量和总样本数\n",
    "    for X, y in train_iter:\n",
    "        y_hat = net(X)  # 前向传播\n",
    "        l = loss(y_hat, y).sum()  # 计算损失\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            updater.zero_grad()  # 清零梯度\n",
    "            l.backward()  # 反向传播\n",
    "            updater.step()  # 更新参数\n",
    "        else:\n",
    "            l.sum().backward()  # 手动反向传播\n",
    "            updater(X.shape[0])  # 更新参数\n",
    "        metric.add(l.item(), accuracy(y_hat, y), y.numel())  # 累加损失、正确预测数量和样本数\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]  # 返回平均损失和准确率"
   ],
   "id": "9aff8458210aa9c8",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:01:34.367234Z",
     "start_time": "2025-06-24T13:01:34.363150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)  # 训练一个epoch\n",
    "        test_acc = evaluate_accuracy(net, test_iter)  # 在测试集上评估准确率\n",
    "        print(f'epoch {epoch + 1}, loss {train_metrics[0]:f}, '\n",
    "              f'train acc {train_metrics[1]:f}, test acc {test_acc:f}')"
   ],
   "id": "d7a21b1e69eaa839",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:01:34.381382Z",
     "start_time": "2025-06-24T13:01:34.376240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sgd(params, lr, batch_size):\n",
    "    # 小批量随机梯度下降\n",
    "    with torch.no_grad():  # 禁用梯度计算\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size  # .grad 会储存张量在反向传播中计算的梯度\n",
    "            param.grad.zero_()  # 清零梯度，pytorch不会自动清零"
   ],
   "id": "9a8615883cf00520",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:01:34.394010Z",
     "start_time": "2025-06-24T13:01:34.389682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr = 0.1\n",
    "\n",
    "\n",
    "def updater(batch_size):\n",
    "    return sgd([w, b], lr, batch_size)"
   ],
   "id": "9a3df7ec38925c92",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:01:40.361429Z",
     "start_time": "2025-06-24T13:01:40.294637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X, y = next(iter(train_iter))\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"net(X) shape:\", net(X).shape)\n",
    "print(\"accuracy:\", accuracy(net(X), y))"
   ],
   "id": "7947e0613f8edf4c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([256, 1, 28, 28])\n",
      "y shape: torch.Size([256])\n",
      "net(X) shape: torch.Size([256, 10])\n",
      "accuracy: 23.0\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:04:26.844568Z",
     "start_time": "2025-06-24T13:03:13.604014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 10\n",
    "train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)"
   ],
   "id": "a347c3d503eaea44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.816614, train acc 0.748600, test acc 0.793000\n",
      "epoch 2, loss 0.568907, train acc 0.813833, test acc 0.804400\n",
      "epoch 3, loss 0.525153, train acc 0.825600, test acc 0.813700\n",
      "epoch 4, loss 0.501837, train acc 0.831217, test acc 0.818000\n",
      "epoch 5, loss 0.485123, train acc 0.836467, test acc 0.814200\n",
      "epoch 6, loss 0.474473, train acc 0.840433, test acc 0.820600\n",
      "epoch 7, loss 0.464406, train acc 0.842567, test acc 0.826600\n",
      "epoch 8, loss 0.457551, train acc 0.845550, test acc 0.831100\n",
      "epoch 9, loss 0.452941, train acc 0.846200, test acc 0.835000\n",
      "epoch 10, loss 0.446985, train acc 0.848150, test acc 0.834000\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:06:38.440796Z",
     "start_time": "2025-06-24T13:06:38.429624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''简洁实现'''\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "\n",
    "net.apply(init_weights)  # 初始化权重"
   ],
   "id": "7b47adc4c59ef5bb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:11:27.573450Z",
     "start_time": "2025-06-24T13:11:27.551280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.1)"
   ],
   "id": "6cc09a402c996a2d",
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:12:57.533729Z",
     "start_time": "2025-06-24T13:11:38.326313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 10\n",
    "train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)"
   ],
   "id": "200150d6f4db9f79",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.003081, train acc 0.749650, test acc 0.762800\n",
      "epoch 2, loss 0.002233, train acc 0.813350, test acc 0.807100\n",
      "epoch 3, loss 0.002056, train acc 0.826083, test acc 0.807400\n",
      "epoch 4, loss 0.001962, train acc 0.831700, test acc 0.823300\n",
      "epoch 5, loss 0.001899, train acc 0.837117, test acc 0.824500\n",
      "epoch 6, loss 0.001854, train acc 0.840050, test acc 0.825000\n",
      "epoch 7, loss 0.001818, train acc 0.842667, test acc 0.828800\n",
      "epoch 8, loss 0.001795, train acc 0.845383, test acc 0.823000\n",
      "epoch 9, loss 0.001776, train acc 0.846617, test acc 0.831300\n",
      "epoch 10, loss 0.001756, train acc 0.847800, test acc 0.822700\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "daa0b57257340a4f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
