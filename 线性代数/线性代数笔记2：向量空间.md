# 线性代数笔记2：向量空间

> 参考资料：
>
> 《LINEAR ALGEBRA AND ITS APPLICATIONS》 -- Gilbert Strang
>
> MIT 18.06 线性代数笔记：[linear-algebra-notes](https://github.com/RQTN/linear-algebra-notes)
>
> MIT 18.06：[麻省理工学院 - MIT - 线性代数（我愿称之为线性代数教程天花板）](https://www.bilibili.com/video/BV16Z4y1U7oU/?spm_id_from=333.337.search-card.all.click&vd_source=25c74f8e9aff6eff8b6b407f76329bbf)

## 向量空间与子空间

​		在上一章节中通过消元法讨论了$Ax=b$的一种理解，在这一章节中将从向量空间的角度进一步理解线性代数。

​		从最重要的向量空间开始，$\mathbb{R}^1$表示一维空间，它是一条直线，$\mathbb{R}^2$对应的是$x\text{-}y$平面，$\mathbb{R}^3$表示三维空间，它的向量分量对应三维空间中的点。线性代数的优势在于，向量的维度可以自然地扩展到$n$维，$\mathbb{R}^n$表示所有包含$n$个分量的列向量构成的集合。所有的向量空间均支持加法运算和标量乘法运算，即可以进行线性组合。

​		在线性代数中，我们更加关注的向量空间藏身于标准空间$\mathbb{R}^n$内部。从几何角度看，考虑三维空间$\mathbb{R}^3$中过原点的任意平面，该平面本身即构成一个向量空间。如果将这个平面内的向量乘以一个任意标量，其结果仍然在该平面内，或者平面内的任意两个向量相加后也仍然在该平面内。那么，这种过原点的平面是原空间$\mathbb{R}^3$的一个子空间。

​		向量空间的子空间是一个非空子集，且满足向量空间的要求：线性组合仍属于该子空间。

- 若子空间中任意向量$x$和$y$相加，则$x+y$属于该子空间
- 若子空间中任意向量$x$乘以标量$c$，则$cx$属于该子空间

​		子空间对加法和标量乘法闭合，运算规则与原空间一致，从而保证结果仍然在子空间内。特别的，零向量必属于每个子空间。最小的子空间$\mathbb{Z}$仅包含零向量，这是最小的向量空间。而最大的子空间则是整个原空间，比如，原空间为$\mathbb{R}^3$时，可能的子空间包括：$\mathbb{R}^3$本身、过原点的平面、过原点的直线或仅包含原点的零空间。

​		在这里，可以举例说明子集和子空间的区别。

​		现考虑$\mathbb{R}^2$中所有分量非负的向量构成的子集，即第一象限，然而该子集并不是子空间。若标量为$-1$，向量为$[1, 1]$，则$c \cdot x = [-1, -1]$落入第三象限；若加法运算$[1, 2] + [-2, -1] = [-1, 1]$，其结果不属任一象限。因此，包含第一象限的最小子空间是完整的$\mathbb{R}^2$。

​		在了解了向量空间和子空间的概念后，接下来将介绍矩阵$A$的列空间$C(A)$和零空间$N(A)$。

### 列空间

​		列空间包含$A$各列的所有线性组合，它是$\mathbb{R}^m$的子空间。下面以一个包含$m=3$个方程、$n=2$个未知数的系统来说明：
$$
\begin{bmatrix}
1 & 0 \\
5 & 4 \\
2 & 4
\end{bmatrix}
\begin{bmatrix}
u \\
v
\end{bmatrix}
=
\begin{bmatrix}
b_1 \\
b_2 \\
b_3
\end{bmatrix}
.\tag{2-1}
$$
​		当$m>n$，即方程数大于未知数时，方程组通常无解，在如以下情况时有解：方程组$Ax=b$有解当且仅当向量$b$可表示为$A$各列的线性组合，此时$b$属于列空间。这本质上是将$Ax=b$按列拆分：
$$
u \begin{bmatrix} 1 \\ 5 \\ 2 \end{bmatrix} + v \begin{bmatrix} 0 \\ 4 \\ 4 \end{bmatrix} = \begin{bmatrix} b_1 \\ b_2 \\ b_3 \end{bmatrix}.\tag{2-2}
$$
​		可以将问题转化为：找到系数$u$和$v$，使得列的线性组合生成$b$。当且仅当这样的系数存在时，方程组有解，且解为向量$(u,v)$。

<img src="C:\Users\ChuantaoLi\AppData\Roaming\Typora\typora-user-images\image-20250204172426230.png" alt="image-20250204172426230" style="zoom:50%;" />

<center>
    图2-1 列空间示意图
</center>

​		所有可能的右侧向量$b$均属于由$ A $的列张成的平面，如图2-1所示。例如，$ b $可以是第一列 ($ u = 1, v = 0 $)、第二列 ($ u = 0, v = 1 $) 或零向量 ($ u = 0, v = 0 $)。若$ b $不在该平面内，则方程组无解。此平面不仅是$\mathbb{R}^3$的子集，更是一个子空间——称为$ A $的列空间，记为$ C(A) $。

### 零空间

​		零空间是方程组$Ax=0$的解集，记为$N(A)$，它是$\mathbb{R}^n$的子空间。当齐次方程时：
$$
\begin{bmatrix}
1 & 0 \\
5 & 4 \\
2 & 4
\end{bmatrix}
\begin{bmatrix}
u \\
v
\end{bmatrix}
=
\begin{bmatrix}
0 \\
0 \\
0
\end{bmatrix}.\tag{2-3}
$$
​		此时解为$u=0$，$v=0$，零空间仅含$(0,0)$。

​		当矩阵存在线性相关的列时：
$$
\begin{bmatrix}
1 & 0 & 1 \\
5 & 4 & 9 \\
2 & 4 & 6
\end{bmatrix}
\begin{bmatrix}
c \\
c \\
-c
\end{bmatrix}
=
\begin{bmatrix}
0 \\
0 \\
0
\end{bmatrix}.\tag{2-4}
$$
​		其第三列为前两列之和，零空间包含向量$(1, 1, -1)$及其倍数$(c, c, -c)$，即一条穿过原点的直线。零空间与列空间共同构成与矩阵$A$密切相关的四个基本子空间，后续将深入探讨其维度与生成方式。

## 求解$Ax=0$

​		在第一章的内容中，主要讨论了方阵和可逆矩阵。在这一小节中，开始讨论线性方程组$Ax=b$的解的结构，尤其是$A$为非方阵的情况。然而对于非方阵的情况，我们通过通过消元法得到行阶梯形矩阵$U$，再化简成最简行阶梯形矩阵$R$去求解。

​		行阶梯形矩阵$U$指的是：

- 主元是每行中第一个非零元素。
- 每个主元下方是通过消元得到的一列零。
- 每个主元位于上一行主元的右侧。这产生了阶梯模式，零行在最后。

​		行最简阶梯形矩阵$R$相对于$U$，会通过消元法使得所有主元都为1，并且主元的上下都为0。当$A$可逆的时候，$R$为单位矩阵。

​		在消元过程中，首先要明确$A$的零空间不会改变。因为零空间是方程组$Ax=0$的解集，行变换的三种操作：交换方程顺序（行交换）、缩放方程和方程的线性组合（行加减），都不会改变解。这些操作相当于$A$左乘一个可逆矩阵$E$，因此方程组$EAx=0$与原方程组$Ax=0$的解集完全相同，零空间不会因为行变换而改变。

​		实际上，消元过程改变的是列空间。列空间是矩阵列向量的所有线性组合构成的子空间。行变换会直接修改列向量的分量：

​		设原矩阵$ A = \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix} $，列空间由$\begin{bmatrix} 1 \\ 3 \end{bmatrix}$和$\begin{bmatrix} 2 \\ 4 \end{bmatrix}$张成。行变换后（如第二行减去3倍第一行）：新矩阵$ EA = \begin{bmatrix} 1 & 2 \\ 0 & -2 \end{bmatrix} $，列向量变为$\begin{bmatrix} 1 \\ 0 \end{bmatrix}$和$\begin{bmatrix} 2 \\ -2 \end{bmatrix}$。显然，新列空间由不同的向量张成，与原列空间不同。这是因为行变换改变了列向量的具体数值，导致它们的线性组合关系变化，因此列空间被改变。

​		现在以矩阵$A$为例，再次说明为什么列空间会随着行变换而发生变化：
$$
A=\begin{bmatrix}
1 & 2 & 2 & 2 \\
2 & 4 & 6 & 8 \\
3 & 6 & 8 & 10
\end{bmatrix}.\tag{2-5}
$$
​		首先对矩阵$A$进行消元，可见有两个主元：1和2，其消元过程如下所示：
$$
\begin{bmatrix} 1 & 2 & 2 & 2 \\ 2 & 4 & 6 & 8 \\ 3 & 6 & 8 & 10 \end{bmatrix} \xrightarrow{r_2 = r_2 - 2 \times r_1} \begin{bmatrix} 1 & 2 & 2 & 2 \\ 0 & 0 & 2 & 4 \\ 0 & 0 & 2 & 4 \end{bmatrix} \xrightarrow{r_3 = r_3 - r_2} \begin{bmatrix} 1 & 2 & 2 & 2 \\ 0 & 0 & 2 & 4 \\ 0 & 0 & 0 & 0 \end{bmatrix}.\tag{2-6}
$$
​		可见消元后的矩阵$U$的所有列向量的第三行都为0，无法线性组合成$A$中的任何一个列向量。从这个例子得出的观点是，对于有些矩阵而言，行变换并不改变其列空间，这样的矩阵往往是在每一行都有主元存在。

​		继续观察式(2-6)，发现第二列没有主元，这表示第二列是其前面列的一个线性组合，显然第二列是第一列的两倍；第四列没有主元，所以第四列是其前面列的一个线性组合，显然第四列等于两倍的第三列减去第二列。这就是列的线性相关性，对于行而言同理。

​		进一步的，我们可以得出一个结论：如果一个矩阵有$r$个主元，那么该矩阵有$r$列线性无关，有$r$行线性无关。并且，我们将矩阵中主元的个数称为秩。

​		在对矩阵$A$化简成阶梯形后，求解问题$Ax=0$变成了$Ux=0$。首先要对自由变量赋予任意值，一般来说一个自由变量赋值1，其他的自由变量赋值0：
$$
\left\{
\begin{array}{l}
x_1 + 2x_2 + 2x_3 + 2x_4 = 0 \\
2x_3 + 4x_4 = 0
\end{array}
\right.
\xrightarrow{}
\left\{
\begin{array}{l}
x_1 = 2x_4 - 2x_2 \\
x_3 = -2x_4
\end{array}
\right..\tag{2-7}
$$
​		首先给自由变量$\begin{bmatrix} x_2 \\ x_4 \end{bmatrix}$赋值为$\begin{bmatrix} 1 \\ 0 \end{bmatrix}$，代入方程组得到解向量为$\begin{bmatrix} -2 \\ 1 \\ 0 \\ 0 \end{bmatrix}$。再给自由变量$\begin{bmatrix} x_2 \\ x_4 \end{bmatrix}$赋值为$\begin{bmatrix} 0 \\ 1 \end{bmatrix}$，代入方程组得到解向量为$\begin{bmatrix} 2 \\ 0 \\ -2 \\ 1 \end{bmatrix}$。这两个解称之为特解，需要注意的是，取0和取1的好处是，得到的特解之间一定是线性无关的，正是因为这样，才能保证$k$（自由变量的个数）个特解能够完整地表示整个零空间。因此，解空间由以下两个特解张成：
$$
x = s \begin{bmatrix} -2 \\ 1 \\ 0 \\ 0 \end{bmatrix} + t \begin{bmatrix} 2 \\ 0 \\ -2 \\ 1 \end{bmatrix}, \quad s, t \in \mathbb{R}.\tag{2-8}
$$

## 求解$Ax=b$

​		线性方程组$Ax=b$不一定有解，其可解性可以通过消元来反映。继续以上一小节的例子：
$$
\begin{bmatrix}
1 & 2 & 2 & 2 & b_1 \\
2 & 4 & 6 & 8 & b_2 \\
3 & 6 & 8 & 10 & b_3
\end{bmatrix}
\xrightarrow{}
\begin{bmatrix}
1 & 2 & 2 & 2 & b_1 \\
0 & 0 & 2 & 4 & b_2 - 2b_1 \\
0 & 0 & 2 & 4 & b_3 - 3b_1
\end{bmatrix}
\xrightarrow{}
\begin{bmatrix}
1 & 2 & 2 & 2 & b_1 \\
0 & 0 & 2 & 4 & b_2 - 2b_1 \\
0 & 0 & 0 & 0 & b_3 - b_2 - b_1
\end{bmatrix}.\tag{2-9}
$$
​		从最后一行可以看出，要使$Ax=b$有解，则必须满足$b_3-b_2-b_1=0$，这是因为$b$必须要属于$A$的列空间，即必须是$A$各列的线性组合。

​		我们继续考虑上面的矩阵，假设$ b = \begin{bmatrix} 1 \\ 5 \\ 6 \end{bmatrix} $满足可解性条件，那么整个$ Ax = b $包括2个方程，但未知数有4个，理论上应该能够找出很多解：
$$
\left\{ \begin{array}{l} x_1 + 2x_2 + 2x_3 + 2x_4 = 1 \\ 2x_3 + 4x_4 = 3 \end{array} \right..\tag{2-10}
$$
​		我们先找出一个特解，策略是将所有自由变量取0，然后求出$ Ax = b $中的所有主变量的值。下面求出特解$ x_p $：

​		首先令$x_2 = 0, x_4 = 0$，有：
$$
\left\{ \begin{array}{l} x_1 + 2x_3 = 1 \\ 2x_3 = 3 \end{array} \right.,\tag{2-11}
$$
可求解出$ x_1 = -2, x_3 = \frac{3}{2}$，因此特解$x_p$为：
$$
x_p = \begin{bmatrix} -2 \\ 0 \\ \frac{3}{2} \\ 0\end{bmatrix}.\tag{2-12}
$$
​		将第一步所得的特解$ x_p $加上零空间中的任意向量（设为 $ x_n $）即可得到所有解（通解）$ x = x_p + x_n $。从计算上这很好理解，那么从几何角度上看呢？一个经过原点的平面表示零空间，然后整个零空间加上一个特解，表示平面的平移，最后这个平面不再经过原点，这也意味着所得解并非是一个向量空间。

​		下面讨论在有解的情况下，$Ax=b$解的情况。

​		考虑秩为$r$的$m\times n$矩阵$A$，显然有$r\le m$且$r\le n$，首先讨论满秩的情况：

- 列满秩时，即$r=n$，每一列都有主元，因此没有自由列没有自由变量，零空间只包含零向量。只要$b$满足可解性，即$Ax=b$有解，那么这个解就是唯一解。值得一提的是，这个解还是特解，因为特解加上零向量还是其本身。
- 行满秩时，即$r=m$，每一行都有主元，那么在消元时不会出现零行，因此对$b$没有要求，即必然有解。在这种情况下需要分析$r=m<n$和$r=m=n$两种情况：
  - $r=m<n$：存在$n-r$个自由变量，即零空间除了包含零向量外，还包含$n-r$个特解的线性组合，那么在这种情况下存在多个解。
  - $r=m=n$：不存在自由变量，即零空间只包含零向量，那么这种情况下存在唯一解。而且，此时$A$是一个可逆矩阵。

| 条件 | R 的形式 | 解的情况 |
|------|----------|----------|
| $ r = m = n $ | $ R = I $ | 存在唯一解 |
| $ r = n < m $ | $ R = \begin{bmatrix} I \\ 0 \end{bmatrix} $ | 存在唯一解或无解（出现 0 行对 $ b $ 有要求） |
| $ r = m < n $ | $ R = \begin{bmatrix} I & F \end{bmatrix} $ | 存在无穷解 |
| $ r < m, r < n $ | $ R = \begin{bmatrix} I & F \\ 0 & 0 \end{bmatrix} $ | 存在无穷解或无解（出现 0 行对 $ b $ 有要求） |

## 线性无关、基、维度

​		这一小节的目标是解释和使用四个概念：

1. 线性无关或线性相关。
2. 生成子空间。
3. 子空间的基（一组向量）。
4. 子空间的维数（一个数字）。

### 线性无关

​		假设$c_1v_1 + ··· + c_kv_k = 0$仅当$c_1 = ··· = c_k = 0$时成立，那么向量$v_1, …, v_k$是线性无关的。如果任何$c_i$不为零，则$v_i$是线性相关的，一个向量是其他向量的组合。

​		线性相关在三维空间中很容易可视化，假设所有向量从原点出发，如果两个向量位于同一条线上，则它们是相关的；如果三个向量位于同一平面上，则它们是相关的。在$R^3$中，四个向量总是线性相关的。如果$v_1$是零向量，则该向量组是线性相关的。我们可以选择$c_1 = 3$且所有其他$c_i = 0$。

​		对于如下矩阵
$$
A =
\begin{bmatrix}
1 & 3 & 3 & 2 \\
2 & 6 & 9 & 5 \\
-1 & -3 & 3 & 0
\end{bmatrix},\tag{2-13}
$$
是线性相关的，因为第二列是第一列的三倍。权重为-3, 1, 0, 0的列组合生成零列。

​		再考虑这个上三角矩阵
$$
A = \begin{bmatrix} 3 & 4 & 2 \\ 0 & 1 & 5 \\ 0 & 0 & 2 \end{bmatrix},\tag{2-14}
$$
我们求解$Ac=0$有：
$$
c_1 \begin{bmatrix} 3 \\ 0 \\ 0 \end{bmatrix} + c_2 \begin{bmatrix} 4 \\ 1 \\ 0 \end{bmatrix} + c_3 \begin{bmatrix} 2 \\ 5 \\ 2 \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix}.\tag{2-15}
$$
​		只有当$c_1,c_2,c_3=0$时才成立，所以当且仅当$N(A)$只有零向量时，$A$的列是独立的。

​		对于行阶梯形矩阵$U$：
$$
U = \begin{bmatrix} 1 & 3 & 3 & 2 \\ 0 & 0 & 3 & 1 \\ 0 & 0 & 0 & 0 \end{bmatrix},\tag{2-16}
$$
显然保证独立的列就是包含主元的列。

​		对于行阶梯矩阵$U$和行最简阶梯矩阵$R$，有$r$个非零行是线性无关的，包含主元的$r$列也是线性无关的。

​		如果$n>m$，在每个$m\times n$系统$Ax=0$都有非零解，这些在$\mathbb{R}^2$中的三列是不可能独立的。

### 生成子空间

​		向量组$v_1,v_2,\cdots,v_n$生成一个向量空间的意思是，这个向量空间包含这些向量的所有线性组合，比如矩阵的列的所有线性组合生成了它的列空间。但需要注意的是，向量组$v_1,v_2,\cdots,v_n$可能是线性相关的，比如向量$v_1 = (1, 0, 0)$、$v_2 = (0, 1, 0) $和$v_3 = (-2, 0, 0) $生成$\mathbb{R}^3$中的一个平面，前两个向量也生成这个平面，而$v_1 $和$v_3 $只生成一条线。

​		单位矩阵的坐标向量$e_1, ..., e_n$生成$\mathbb{R}^n$，任意向量$b = (b_1, ..., b_n) $都是这些列的组合。在这个例子中，权重是分量$b_i$本身：$b = b_1e_1 + ... + b_ne_n$，以$\mathbb{R}^3$为例：
$$
b = \begin{bmatrix} b_1 \\ b_2 \\ b_3 \end{bmatrix} = b_1 \begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix}+b_2
\begin{bmatrix}
0 \\
1 \\
0
\end{bmatrix}+

b_3
\begin{bmatrix}
0 \\
0 \\
1
\end{bmatrix}.\tag{2-17}
$$
​		由上式可知，没有一列是浪费的，坐标向量$e_1, ..., e_n$生成的$\mathbb{R}^n$它们是线性无关的，这可以引出基的概念。

### 基

​		$V$的基是具有两个属性的向量序列：

1. 向量是线性无关的。
2. 它们生成空间$V$。

​		这种属性组合对线性代数至关重要。这意味着空间中的每个向量都是基向量的组合，因为基向量生成了空间，且这也意味着组合是唯一的。

​		到了这里，我们可以知道坐标向量$ e_1, \ldots, e_n $不是$ \mathbb{R}^n $唯一的基向量。向量空间有无限多个不同的基。比如，每当方阵可逆时，它的列是独立的，因此它们是$ \mathbb{R}^n $的基。这个非奇异矩阵的两列是$ \mathbb{R}^2 $的基：
$$
A = \begin{bmatrix} 1 & 1 \\ 2 & 3 \end{bmatrix} \quad \text{和} \quad \begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix}.\tag{2-18}
$$
​		$ \mathbb{R}^2 $中的每个二维向量都是这些列的组合。

​		对于式(2-16)的阶梯形矩阵而言，包含主元的列是独立的，因此它们是列空间的基。到这里我们可以得出结论，任何矩阵的列生成其列空间，如果它们是独立的，则是列空间的基。无论矩阵是方阵还是矩形的，如果要求列是整个空间$\mathbb{R}^n$的基，则矩阵必须的方阵且可逆。

### 空间的维数

​		对于某个特定的向量空间，其对应的基是无穷多个的，但这些基都有共同点：基所包含的向量（基向量）的个数是一定的。而这个确定的基向量的个数实际上就表示了向量空间的大小，我们一般称其为向量空间的维数。

​		矩阵$A$的秩$\text{rank}(A)$是主元列的个数，也是矩阵$A$列空间的维数；而$n-\text{rank}(A)$是自由列的个数，也是零空间的维数。

## 四个基本子空间

​		这里是线性代数的核心内容，四个基本子空间分别是：列空间$C(A)$、零空间$N(A)$、行空间$C(A^T)$、左零空间$N(A^T)$。现在考虑一个$m\times n$的矩阵$A$，以此讨论四个基本子空间。

​		对于零空间$N(A)$来说，它是$Ax=0$的解，是一个$n$维的向量，所以是$\mathbb{R}^n$的子空间；对于列空间$C(A)$来说，它是所有列线性组合的结果，每一列都是$m$维空间中的向量，那么这些列向量张成的空间就是一个$m$维空间中的子空间，所以$C(A)$是$\mathbb{R}^m$的子空间；对于行空间$C(A^T)$一种思考方式是将矩阵$A$进行转置，和$C(A)$相反，行空间是$\mathbb{R}^n$的子空间；同理，左零空间$N(A^T)$则是$\mathbb{R}^m$的子空间。

​		在解决如何为这些子空间分别构建一组基之前，我们需要讨论这四个基本子空间的维数，因为我们得先知道需要使用多少个向量才能组成一组基。

​		对于列空间$C(A)$而言，其维数为秩数$r$，是主元列的数量，因为线性相关的自由列对子空间的生成没有作用。很显然，列空间$C(A)$的一组基就是它的主列。

​		对于零空间$N(A)$，它是$Ax=0$的解，我们知道每个特解都是从自由变量得出的，它们组成了零空间的一组基。所以，零空间的维数是$n-r$。

​		对于行空间$C(A^T)$而言，其维数也为秩数$r$，行秩等于列秩是一个性质。现在考虑矩阵$A$经过消元法得到行最简阶梯式$R$：
$$
A = \begin{bmatrix} 1 & 2 & 3 & 1 \\ 1 & 1 & 2 & 1 \\ 1 & 2 & 3 & 1 \end{bmatrix} \rightarrow \begin{bmatrix} 1 & 0 & 1 & 1 \\ 0 & 1 & 1 & 0 \\ 0 & 0 & 0 & 0 \end{bmatrix}=R
$$
​		可以发现行变换改变了列空间，即$C(A)\neq C(R)$，比如向量$\begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix}$在$A$的列空间中，但却不在$R$的列空间中。具体而言，一个第三行为全零的矩阵$R$，其向量组无法线性组合出一个第三维不为零的向量。但是，行变换并未改变行空间，初等行变换包括包括： 交换两行、某行乘以非零常数和某行加上另一行的倍数，这些操作仅通过线性组合生成新的行，因此变换后的行向量仍是原行向量的线性组合。

​		我们可以验证这一结论，$A$中的任意一个行向量，都可以由$R$中的两个主元线性变换得到，这表明其行空间没有发生变化。对于行空间，它的一组基为$R$的前$r$个行向量，这$r$个行向量间线性无关。那为什么$A$的各行会是这组基的线性组合？这是因为初等行变换是可逆的，存在可逆矩阵$P$（初等行变换的乘积），使得$PA=R$。因此，$A=P^{−1}R$，即$A$的行是$R$的行的线性组合。

​		对于左零空间$N(A^T)$，假设其包含一些向量$y$，那么有$A^Ty=0$。但左零空间是针对$A$而言的，并不是针对$A^T$，我们可以进行转置，进而得到$y^TA=0$，其中$y^T$位于$A$的左边，这也是$A$左零矩阵的由来。

​		对于左零空间的讨论，可以从高斯若尔当消元法的角度出发。回顾在对可逆方阵$A$的讨论中，我们知道如下消元操作：
$$
E[A,I]\rightarrow[I,A^{-1}]
$$
​		但是我们现在所讨论的矩阵$A$并不是方阵，假如我们进行行最简阶梯形的化简，有：
$$
\text{rref}[A,I]\rightarrow[R,E]
$$
​		这个$E$记录了消元过程中$A$的所有初等行变换，即$EA=R$。现在我们可以找出$E$到底是什么：
$$
EA=\begin{bmatrix}
-1 & 2 & 0 \\
1 & -1 & 0 \\
-1 & 0 & 1
\end{bmatrix}
\begin{bmatrix} 1 & 2 & 3 & 1 \\ 1 & 1 & 2 & 1 \\ 1 & 2 & 3 & 1 \end{bmatrix} =\begin{bmatrix} 1 & 0 & 1 & 1 \\ 0 & 1 & 1 & 0 \\ 0 & 0 & 0 & 0 \end{bmatrix}=R
$$
​		观察上式的变换可知，$R$的第三行出现了零行，这说明$E$的第三行对$A$的各行的线性组合恰好能够得到一个零行。最后结合$y^TA=0$，我们可以发现$E$的第三行正是$y^T$。基于这个思路，我们可以很方便地得出左零空间$N(A^T)$维数和一组基分别是什么。维数是零行的个数，即$m-r$。在这个例子中，$E$的第三行就构成了左零空间的一组基。

## 矩阵空间、秩1空间

​		在这一章节的最后，我们可以把矩阵也看成是“向量”，因为矩阵也满足向量之间的运算律，甚至存在某种线性组合的结果为零矩阵，我们可以把矩阵看作是特殊的向量空间。

​		假设现在有一个由所有$3\times 3$的矩阵组成的矩阵空间$\mathbb{R}^{3\times 3}$，简记为$M$。显然，它有一组标准基，由9个$3\times 3$的矩阵组成，每个矩阵在不同的某个位置上取1，其他位置取0，所以$M$的维数是9。

​		我们也可以找出它可能的子空间，它需要满足包含零矩阵，以及对加法和标量乘法封闭，比如所有的上三角矩阵、所有的对称矩阵，以及这二者的交集：所有的对角矩阵。

​		对于对称矩阵$S$而言，它的维度是6，它的一组基是：
$$
\begin{bmatrix}
1 & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & 0
\end{bmatrix},
\begin{bmatrix}
0 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 0
\end{bmatrix},
\begin{bmatrix}
0 & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & 1
\end{bmatrix},
\begin{bmatrix}
0 & 1 & 0 \\
1 & 0 & 0 \\
0 & 0 & 0
\end{bmatrix},
\begin{bmatrix}
0 & 0 & 1 \\
0 & 0 & 0 \\
1 & 0 & 0
\end{bmatrix},
\begin{bmatrix}
0 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix}
$$
​		对于上三角矩阵$U$而言，它的维度是6，它的一组基是：
$$
\begin{bmatrix}
1 & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & 0
\end{bmatrix},
\begin{bmatrix}
0 & 1 & 0 \\
0 & 0 & 0 \\
0 & 0 & 0
\end{bmatrix},
\begin{bmatrix}
0 & 0 & 1 \\
0 & 0 & 0 \\
0 & 0 & 0
\end{bmatrix},
\begin{bmatrix}
0 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 0
\end{bmatrix},
\begin{bmatrix}
0 & 0 & 0 \\
0 & 0 & 1 \\
0 & 0 & 0
\end{bmatrix},
\begin{bmatrix}
0 & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & 1
\end{bmatrix}
$$
​		对于其他的子空间，我们采取的一个方法是，取对称矩阵和上三角矩阵的交集$S\cap U$，即对角矩阵$D$，它的一组基是：
$$
\begin{bmatrix}
1 & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & 0
\end{bmatrix},
\begin{bmatrix}
0 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 0
\end{bmatrix},
\begin{bmatrix}
0 & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & 1
\end{bmatrix}
$$
​		在考虑了交集后我们会想到，它们的交集会是什么情况？而事实上，两个子空间的交集并不一定是子空间，我们可以考虑二维向量空间$\mathbb{R}^2$​中的例子。

​		设子空间$U = \{(x, 0) | x \in \mathbb{R}\}$（$x$轴）和子空间$W = \{(0, y) | y \in \mathbb{R}\}$（$y$轴）。显然，$U$和$W$都是$\mathbb{R}^2$的子空间，因为它们都包含零向量，并且对加法和数乘封闭。考虑它们的并集$U \cup W$，它包含所有$x$轴或$y$轴上的向量。取向量$u = (1, 0) \in U$和向量$v = (0, 1) \in W$，它们的和为$u + v = (1, 1)$。这个和向量$(1, 1)$既不在$x$轴$U$上，也不在$y$轴$W$上，因此不属于$U \cup W$。这说明 $U \cup W$ 对加法不封闭，从而不是$\mathbb{R}^2$的子空间。

​		那么，我们考虑$S+U$，这表示的是任意$S$中的元素加上任意$U$的元素所组成的一个矩阵空间，显然这就是$M$，因此维数为9。

​		联系上面四种情况，有如下等式成立：
$$
dim(S) + dim(U) = dim(S ∩ U) + dim(S + U)
$$
​		接下来，将向量空间的概念进行拓展，考虑如下微分方程：
$$
\frac{d^2y}{dx^2} + y = 0
$$
​		只考虑实数范围，很容易可以找到两个特解：$y = \sin x$ 和 $y = \cos x$，且这个微分方程的通解是$y=c_1 \sin x + c_2 \cos x$。我们延续刚刚向量空间的概念，当然对于这个问题来说是解空间，$\sin x$和$\cos x$就是向量空间的一组基，所有$\sin x$和$\cos x$的线性组合，则是该微分方程的向量空间，且维数为2。

​		我们现在讨论秩为1的矩阵，以下面这个矩阵为例：
$$
A = 
\begin{bmatrix}
1 & 4 & 5 \\
2 & 8 & 10
\end{bmatrix}
$$
​		很显然，这个$2\times 3$的矩阵$A$中，第二行可以是第一行的任意倍，因此这个矩阵的行向量间线性相关，列向量间也都是线性相关。那么，对于所有的秩为1的矩阵，都可以写成一列乘一行的形式，仍以矩阵$A$为例：
$$
\begin{bmatrix}
1 & 4 & 5 \\
2 & 8 & 10
\end{bmatrix}

= 

\begin{bmatrix}
1 \\
2
\end{bmatrix}


\begin{bmatrix}
1 & 4 & 5
\end{bmatrix}

= UV^T
$$
​		除此之外，任何秩为$r$的矩阵，都可以分解为$r$个秩1矩阵的和，这可以从“列乘行”的矩阵乘法角度去理解。但矩阵的加法存在这样的性质：$\text{rank}(A+B)\le \text{rank}(A)+\text{rank}(B)$。比如设$ A = \begin{bmatrix} 1 & 0 \\ 0 & 0 \end{bmatrix} $（秩1），$ B = \begin{bmatrix} 0 & 0 \\ 0 & 1 \end{bmatrix} $（秩1）。则$ A + B = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} $，秩为2，此时$\text{rank}(A + B) = \text{rank}(A) + \text{rank}(B) = 2$​。再比如设$ A = \begin{bmatrix} 1 & 0 \\ 0 & 0 \end{bmatrix} $（秩1），$ B = \begin{bmatrix} 2 & 0 \\ 0 & 0 \end{bmatrix} $（秩1）。则$ A + B = \begin{bmatrix} 3 & 0 \\ 0 & 0 \end{bmatrix} $，秩仍为1，此时$\text{rank}(A + B) = 1 < 1 + 1 = 2$。

​		这个结论说明，对于同样规模的同秩矩阵所组成的集合，其加法是不封闭的，比如两个秩为4的$5\times 6$矩阵相加，秩可能大于4。基于此，我们还可以讨论所有秩为4的矩阵集合是不是子空间，注意这里不是线性组合，而是集合。答案为不是。

​		如果所有秩为4的矩阵组成的是子空间，那么任意两个秩为4的矩阵相加也应该属于这个空间，即任意两个秩为4的矩阵相加也应该是秩为4的矩阵，但是他们相加的结果可能不是秩为4的矩阵。

​		

​		
